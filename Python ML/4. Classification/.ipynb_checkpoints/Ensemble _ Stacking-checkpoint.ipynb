{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack base model 생성\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV기반의 스태킹\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# for step 1\n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=0)\n",
    "    \n",
    "    # 메타모델이 사용할 학습 테이터 반환 위한 데이터 초기화\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
    "    print(model.__class__.__name__, 'model start ##')\n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        print('\\t fold set: ', folder_counter, ' start')\n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n[valid_index]\n",
    "        \n",
    "        # fold data set으로 training\n",
    "        model.fit(X_tr, y_tr)\n",
    "        # 예측값 메타모델 학습 위해 저장\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        # test set 전체에 대한 예측 결과 따로 저장\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "        \n",
    "    # 위의 fold set 내에서 원본 테스트 데이터를 예측한 데이터를 평균내 테스트 데이터로 생성\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)\n",
    "    \n",
    "    # train_fold_pred는 최종 메타모델이 학습 위해 사용하는 데이터, test_pred_mean은 테스트위한 데이터\n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "# 최종 메타모델\n",
    "lr_final = LogisticRegression(C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kjh58\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "C:\\Users\\kjh58\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier model start ##\n",
      "\t fold set:  0  start\n",
      "\t fold set:  1  start\n",
      "\t fold set:  2  start\n",
      "\t fold set:  3  start\n",
      "\t fold set:  4  start\n",
      "\t fold set:  5  start\n",
      "\t fold set:  6  start\n",
      "RandomForestClassifier model start ##\n",
      "\t fold set:  0  start\n",
      "\t fold set:  1  start\n",
      "\t fold set:  2  start\n",
      "\t fold set:  3  start\n",
      "\t fold set:  4  start\n",
      "\t fold set:  5  start\n",
      "\t fold set:  6  start\n",
      "DecisionTreeClassifier model start ##\n",
      "\t fold set:  0  start\n",
      "\t fold set:  1  start\n",
      "\t fold set:  2  start\n",
      "\t fold set:  3  start\n",
      "\t fold set:  4  start\n",
      "\t fold set:  5  start\n",
      "\t fold set:  6  start\n",
      "AdaBoostClassifier model start ##\n",
      "\t fold set:  0  start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kjh58\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "C:\\Users\\kjh58\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t fold set:  1  start\n",
      "\t fold set:  2  start\n",
      "\t fold set:  3  start\n",
      "\t fold set:  4  start\n",
      "\t fold set:  5  start\n",
      "\t fold set:  6  start\n"
     ]
    }
   ],
   "source": [
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test, 7)\n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature data for training shape :  (455, 30)\n",
      "Original feature data for testing shape :  (114, 30)\n",
      "Stacking feature data for training shape :  (455, 4)\n",
      "Stacking feature data for testing shape :  (114, 4)\n"
     ]
    }
   ],
   "source": [
    "# for step 2\n",
    "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "print('Original feature data for training shape : ', X_train.shape)\n",
    "print('Original feature data for testing shape : ', X_test.shape)\n",
    "print('Stacking feature data for training shape : ', Stack_final_X_train.shape)\n",
    "print('Stacking feature data for testing shape : ', Stack_final_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of final meta model: 0.9561\n"
     ]
    }
   ],
   "source": [
    "# 즉, 최종 메타모델은 feature가 4개, 각 model별 record의 예측 결과를 가지고 train을 진행한다.\n",
    "lr_final.fit(Stack_final_X_train, y_train)\n",
    "stack_final = lr_final.predict(Stack_final_X_test)\n",
    "\n",
    "print('Accuracy of final meta model: {0:.4f}'.format(accuracy_score(y_test, stack_final)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
